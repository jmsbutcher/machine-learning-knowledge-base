@prefix mykb: <http://JamesButcher_ML_KnowledgeBase.org/> .

mykb:autoencoder mykb:can_do mykb:anomaly_detection,
        mykb:dimensionality_reduction,
        mykb:feature_extraction,
        mykb:feature_learning,
        mykb:image_compression,
        mykb:machine_translation,
        mykb:noise_reduction,
        mykb:speech_recognition ;
    mykb:description "An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. - Wikipedia;   It learns good representations in the hidden layer, capturing the essence of the input" ;
    mykb:has_advantage mykb:deep_autoencoders_are_much_better_than_PCA_at_extracting_non-linear_features,
        "Accomplishes roughly the same thing as PCA, but with nonlinearity" ;
    mykb:has_disadvantage mykb:requires_training ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Autoencoder" ;
    mykb:subclass_of mykb:unsupervised_learning .

mykb:autoregressive_models mykb:can_do mykb:feature_extraction,
        mykb:image_generation ;
    mykb:description "Used to describe certain time-varying processes. Specifies that the output variable depends linearly on its own previous values and on a stochastic term (an imperfectly predictable term). -Wikipedia;  Given examples from a distribution, generate samples belonging to the same distribution. -CSE598" ;
    mykb:has_advantage "can explicitly estimate likelihood p(x)",
        "pretty good results for generation",
        "simple and stable training process" ;
    mykb:has_disadvantage "cannot provide low-dimensional latent space",
        "inefficient at generation because it is a sequential process, which cannot be parallelized" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Autoregressive_model" .

mykb:bayesian_network mykb:can_do mykb:anomaly_detection,
        mykb:inference,
        mykb:spam_filtering,
        mykb:time_series_forecasting ;
    mykb:description "A probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG). Ideal for taking an event that occurred and predicting the likelihood that any one of several possible known causes was the contributing factor. -Wikipedia" ;
    mykb:has_advantage "can encode conditional independencies" ;
    mykb:has_disadvantage "cannot automatically learn the structure of data; must be encoded manually",
        "must assume prior distributions of variables" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Bayesian_network" .

mykb:convolutional_neural_network mykb:can_do mykb:anomaly_detection,
        mykb:image_classification,
        mykb:natural_language_processing,
        mykb:noise_reduction,
        mykb:recommendation,
        mykb:video_recognition ;
    mykb:description "A type of deep neural network that takes advantage of the hierarchical pattern in data and assembles patterns of increasing complexity using smaller and simpler patterns embossed in their filters. -Wikipedia" ;
    mykb:has_advantage "independent from prior human knowledge in feature extraction",
        "learns optimal filters automatically" ;
    mykb:has_disadvantage mykb:not_interpretable,
        "there are many hyperparameters to optimize" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Convolutional_neural_network" .

mykb:decision_tree mykb:can_do mykb:capture_interactions_in_data,
        mykb:classification,
        mykb:data_visualization,
        mykb:feature_importance,
        mykb:recommendation,
        mykb:regression ;
    mykb:description "A decision tree is a flowchart-like structure in which each internal node represents a test on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules. -Wikiedia" ;
    mykb:has_advantage mykb:interpretable,
        "can deal with data where features interact with each other",
        "can deal with large, complicated, differently-scaled data",
        "can deal with non-linear data",
        "creates good explanations" ;
    mykb:has_disadvantage mykb:unstable,
        "fails to deal with linear relationships without adding splits, which is inefficient",
        "lack of smoothness; slight changes in an input feature can have a big impact on the predicted outcome",
        "only easily interpretable when short" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Decision_tree" .

mykb:generative_adversarial_network mykb:can_do mykb:image_generation ;
    mykb:description "Consists of two neural networks that compete with each other: The generator, which tries to generate realistic images from noise, and the discriminator, which tries to tell whether a given image is real or fake. There are thousands of papers on GANs in the literature and hundreds of applications -ASU CSE598" ;
    mykb:has_advantage "very realistic images" ;
    mykb:has_disadvantage "can be notoriously hard to optimize",
        "does not provide the inference p(x) - the probability of the input image x" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Generative_adversarial_network",
        "https://www.coursera.org/learn/cse598deeplearninginvisualcomputing/lecture/gAijA/generative-adversarial-networks-gans" .

mykb:k-means_clustering mykb:can_do mykb:data_clustering,
        mykb:feature_learning,
        mykb:recommendation ;
    mykb:description "an unsupervised clustering algorithm that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (or centroid), serving as a prototype of the cluster. -Wikipedia, ASU CSE 575" ;
    mykb:has_advantage mykb:very_simple,
        "modifications such as k-means++ compensate for initialization sensitivity" ;
    mykb:has_disadvantage mykb:sensitive_to_initial_parameters,
        "finding the optimal solution is NP-hard" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/K-means_clustering" ;
    mykb:subclass_of mykb:unsupervised_learning .

mykb:k-nearest-neighbors mykb:can_do mykb:anomaly_detection,
        mykb:classification,
        mykb:recommendation ;
    mykb:description "classifies a data point based on the classes of the nearest k neighbors in the feature space; assumes that similar things are near each other" ;
    mykb:has_advantage mykb:strong_consistency_results,
        mykb:very_simple ;
    mykb:has_disadvantage mykb:computationally_expensive_for_large_data_sets,
        "sensitive to the local structure of the data -Wikipedia" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" ;
    mykb:subclass_of mykb:supervised_learning .

mykb:knowledge_representation_and_reasoning mykb:subclass_of mykb:artificial_intelligence .

mykb:lasso mykb:can_do mykb:feature_selection ;
    mykb:description "Introduces sparsity into a linear regression model that has lots of features; performs feature selection and regularization of the selected feature weights; - from Interpretable Machine Learning by Christoph Molnar." ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Lasso_(statistics)" .

mykb:linear_regression mykb:can_do mykb:feature_importance,
        mykb:price_prediction,
        mykb:regression,
        mykb:time_series_forecasting ;
    mykb:description "Models the relationship between a scalar response and one or more explanatory variables. A fitted linear regression model can be used to identify the relationship between a single predictor variable xj and the response variable y when all the other predictor variables in the model are held fixed." ;
    mykb:has_advantage mykb:interpretable,
        mykb:very_simple,
        mykb:widely_used ;
    mykb:has_disadvantage "Assumes constant variance (homoscedasticity)",
        "Assumes independence of errors",
        "loses interpretability when there are more than a few features. Lasso can help with this.",
        "non-linearity has to be hand-crafted" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Linear_regression" ;
    mykb:subclass_of mykb:supervised_learning .

mykb:logistic_regression mykb:can_do mykb:classification,
        mykb:image_classification ;
    mykb:description " The logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, etc. When a cutoff probability is specified, the model acts as a binary classifier. Can also be extended into a multi-class classifier." ;
    mykb:has_advantage mykb:interpretable,
        mykb:very_simple,
        mykb:widely_used ;
    mykb:has_disadvantage "can suffer from Complete Separation - when a feature perfectly separates two classes, the model cannot be trained. In this case, a simple rule would work better anyway. - from Interpretable Machine Learning by Christoph Molnar",
        "interactions must be added manually",
        "other models may have better predictive performance" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Logistic_regression" ;
    mykb:subclass_of mykb:supervised_learning .

mykb:long_short-term_memory mykb:can_do mykb:anomaly_detection,
        mykb:machine_translation,
        mykb:natural_language_processing,
        mykb:speech_recognition,
        mykb:time_series_forecasting ;
    mykb:description "LSTM - A type of recurrent neural network (RNN) that addresses the vanishing gradient problem. A common LSTM unit is composed of a cell, an input gate, an output gate, and a forget gate.   The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell. -Wikipedia" ;
    mykb:has_advantage "does not suffer from the vanishing/exploding gradient problem",
        "relatively insensitive to gap length -Wikipedia" ;
    mykb:has_disadvantage "has many more parameters than other methods" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Long_short-term_memory" .

mykb:naive_bayes mykb:can_do mykb:classification,
        mykb:recommendation ;
    mykb:description "A family of probabilistic classifiers based on applying Bayes theorem with strong (naive) independence assumptions between the features. Often uses maximum likelihood for parameter estimation. -Wikipedia" ;
    mykb:has_advantage mykb:very_simple,
        "actually work quite well in many complex real-world situations -Wikipedia",
        "only requires a small number of training data to estimate the parameters necessary for classification -Wikipedia (no citation)" ;
    mykb:has_disadvantage "outperformed by many other classifiers such as boosted trees or random forests -Wikipedia" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Naive_Bayes_classifier" ;
    mykb:subclass_of mykb:supervised_learning .

mykb:principal_component_analysis mykb:can_do mykb:data_analysis,
        mykb:dimensionality_reduction,
        mykb:feature_extraction,
        mykb:feature_learning ;
    mykb:description "PCA is the process of computing the principal components (the axes with the highest variance - in other words, the most descriptive directions) and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest." ;
    mykb:has_advantage "Generates *new* features that may be highly descriptive of the data, as opposed to mere feature selection -ASU CSE 575" ;
    mykb:has_disadvantage "Assumes linearity of data; but non-linear extensions exist",
        "when multiple classes overlap in one of the non-principal component dimensions, misclassification will get bad. In such cases, Linear Discriminant Analysis (LDA) may be a better approach." ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Principal_component_analysis" ;
    mykb:subclass_of mykb:unsupervised_learning .

mykb:random_forest mykb:can_do mykb:classification,
        mykb:regression ;
    mykb:description "An ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees. -Wikipedia" ;
    mykb:has_advantage "Corrects for decision trees habit of overfitting their training sets",
        "Robust to outlying observations",
        "generally outperforms decision trees -Wikipedia" ;
    mykb:has_disadvantage mykb:not_interpretable ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Random_forest" ;
    mykb:subclass_of mykb:supervised_learning .

mykb:recurrent_neural_network mykb:can_do mykb:machine_translation,
        mykb:natural_language_processing,
        mykb:speech_recognition,
        mykb:time_series_forecasting ;
    mykb:description "A class of artificial neural networks where feedback connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. RNNs can use their internal state (memory) to process variable length sequences of inputs. -Wikipedia" ;
    mykb:has_advantage "has fewer parameters than LSTM" ;
    mykb:has_disadvantage "suffers from vanishing/exploding gradient problem" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Recurrent_neural_network" .

mykb:reinforcement_learning mykb:definition "An area of machine learning where agents acting in an environment learn how to maximize a reward" ;
    mykb:subclass_of mykb:machine_learning .

mykb:spectral_clustering mykb:can_do mykb:graph_clustering ;
    mykb:description "Makes use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions. The similarity matrix is provided as an input and consists of a quantitative assessment of the relative similarity of each pair of points in the dataset. -Wikipedia" ;
    mykb:has_advantage "does not make strong assumptions on the forms of the clusters -ASU CSE 575 course",
        "easy and efficient even for large data sets as long as the similarity graph is sparse",
        "good clustering results" ;
    mykb:has_disadvantage mykb:sensitive_to_initial_parameters ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Spectral_clustering" .

mykb:support_vector_machine mykb:can_do mykb:anomaly_detection,
        mykb:classification,
        mykb:image_classification ;
    mykb:description "An SVM maps training examples to points in space so as to maximize the width of the gap between the two categories. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall. -Wikipedia" ;
    mykb:has_advantage "can handle non-linear classification using kernel trick, mapping inputs into high-dimensional feature spaces",
        "one of the most robust prediction methods -Wikipedia" ;
    mykb:has_disadvantage "requires full labeling of input data" ;
    mykb:is_a mykb:method ;
    mykb:link "https://en.wikipedia.org/wiki/Support-vector_machine" ;
    mykb:subclass_of mykb:supervised_learning .

mykb:support_vector_regression mykb:can_do mykb:regression,
        mykb:time_series_forecasting ;
    mykb:has_advantage "high degree of generalization when introduced to previously unseen data - Jain et.al.",
        "much faster than neural networks on large high-resolution data sets -Forecasting energy consumption of multi-family... by Jain et.al." ;
    mykb:is_a mykb:method ;
    mykb:link "https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/" .

mykb:data_analysis mykb:is_a mykb:application .

mykb:data_clustering mykb:is_a mykb:application .

mykb:graph_clustering mykb:is_a mykb:application .

mykb:image_compression mykb:is_a mykb:application .

mykb:inference mykb:is_a mykb:application .

mykb:price_prediction mykb:is_a mykb:application .

mykb:spam_filtering mykb:is_a mykb:application .

mykb:video_recognition mykb:is_a mykb:application .

mykb:dimensionality_reduction mykb:is_a mykb:application .

mykb:feature_importance mykb:is_a mykb:application .

mykb:image_generation mykb:is_a mykb:application .

mykb:noise_reduction mykb:is_a mykb:application .

mykb:feature_extraction mykb:is_a mykb:application .

mykb:feature_learning mykb:is_a mykb:application .

mykb:image_classification mykb:is_a mykb:application .

mykb:machine_learning mykb:definition "The study of computer algorithms that improve automatically through experience and by the use of data" ;
    mykb:subclass_of mykb:artificial_intelligence .

mykb:machine_translation mykb:is_a mykb:application .

mykb:natural_language_processing mykb:is_a mykb:application .

mykb:speech_recognition mykb:is_a mykb:application .

mykb:unsupervised_learning mykb:subclass_of mykb:machine_learning .

mykb:regression mykb:is_a mykb:application .

mykb:recommendation mykb:is_a mykb:application .

mykb:time_series_forecasting mykb:is_a mykb:application .

mykb:anomaly_detection mykb:is_a mykb:application .

mykb:classification mykb:is_a mykb:application .

mykb:supervised_learning mykb:definition "A subset of machine learning where the model trains on labelled data" ;
    mykb:subclass_of mykb:machine_learning .

